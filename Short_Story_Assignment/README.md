
# Leveraging Customer Feedback for Multi-modal Insight Extraction

This repository contains all materials related to the short story study and presentation of the paper *"Leveraging Customer Feedback for Multi-modal Insight Extraction"* published by Amazon Research in arxiv.

---

## Contents of the Repository
1. **Slide Deck**:
   - A detailed presentation summarizing the paper.
   - File: `Short_Story.pptx`
   - Includes sections like Introduction, Current Limitations, Proposed Solution (MINE), Experimental Setup, Results, and Applications.

2. **Medium Article**:
   - A concise, reader-friendly summary of the paper with insights, comparisons, and practical applications.
   - [Link to Medium Article](https://medium.com/@rishikeshavlal.patel/revolutionizing-customer-feedback-analysis-the-role-of-multi-modal-insight-extraction-mine-fd6806b9c84a)
  
3. **Youtube Video**:
   - [Link to video](https://youtu.be/POpe-jeueEg)

4. **Research Paper**:
   - The original research paper published on *arXiv*.
   - File: `short_story_paper.pdf`
   - Paper Link: [arXiv:2410.09999](https://arxiv.org/abs/2410.09999).

5. **Code for Visualizations**:
   - Python scripts to recreate key graphs and insights used in the Medium article.
   - File: `visualizations.py`

---

## Overview of the Study
### Objective
To develop a novel method to extract actionable insights from multi-modal customer feedback (text and images) using the proposed **MINE (Multi-modal Insight Extraction)** architecture.

![Architecture](https://github.com/user-attachments/assets/90489506-0143-4d42-95d2-a1642cc36417)


### Key Contributions
1. **Weakly-Supervised Learning**: Automatically generates high-quality training data, reducing manual annotation dependency.
2. **Multi-modal Fusion**: Combines text and image inputs in a shared latent space for better contextual understanding.
3. **Significant Performance Gains**: Achieved a 14-point F1-score improvement over baseline models like ALBEF and VL-T5.

---

## Applications
- **Customer Feedback Analysis**: Extract insights to improve product design.
- **Support Automation**: Identify and resolve issues efficiently.
- **Content Moderation**: Filter inappropriate or irrelevant content automatically.

---

## Repository Structure
```plaintext
.
├── Short_Story.pptx              # Slide deck presentation
├── short_story_paper.pdf         # Original research paper
├── visualizations.py             # Python scripts for graphs
├── README.md                     # This file
```

---

## How to Use
1. **Explore the Slide Deck**:
   - Review the key aspects of the survey study.
2. **Read the Medium Article**:
   - Gain an in-depth understanding with additional comparisons and visuals.
3. **Run the Code**:
   - Use `visualizations.py` to generate key graphs used in the Medium article.

---

## References
1. **Original Paper**:  
   Mukku, S., Kanagarajan, A., Ghosh, P., & Aggarwal, C. *"Leveraging Customer Feedback for Multi-modal Insight Extraction."* [arXiv:2410.09999](https://arxiv.org/abs/2410.09999).
   
2. **Related Work**:  
   - Junnan Li et al., *"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation."* ICML 2022.  
   - Alec Radford et al., *"Learning Transferable Visual Models from Natural Language Supervision."* OpenAI, 2021.

---
